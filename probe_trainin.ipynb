{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay, confusion_matrix\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Subset\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain_test_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, test \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextDataset\n",
      "File \u001b[0;32m~/usr_probes/train_test_utils.py:177\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calc_prob_uncertinty\n\u001b[1;32m    178\u001b[0m tic, toc \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime, time\u001b[38;5;241m.\u001b[39mtime)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'losses'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from train_test_utils import train, test \n",
    "import torch.nn as nn\n",
    "from dataset import TextDataset\n",
    "\n",
    "from probes import LinearProbeClassification\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model.half().cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    learning_rate = 1e-3\n",
    "    betas = (0.9, 0.95)\n",
    "    weight_decay = 0.1 # only applied on matmul weights\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    # checkpoint settings\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_socioeco = True\n",
    "\n",
    "new_prompt_format=True\n",
    "residual_stream=True\n",
    "uncertainty = False\n",
    "logistic = True\n",
    "augmented = False\n",
    "remove_last_ai_response = True\n",
    "include_inst = True\n",
    "one_hot = True\n",
    "\n",
    "label_to_id_age = {\"child\": 0,\n",
    "                   \"adolescent\": 1,\n",
    "                   \"adult\": 2,\n",
    "                   \"older adult\": 3,\n",
    "                  }\n",
    "\n",
    "label_to_id_gender = {\"male\": 0,\n",
    "                      \"female\": 1,\n",
    "                     }\n",
    "\n",
    "label_to_id_socioeconomic = {\"low\": 0,\n",
    "                             \"middle\": 1,\n",
    "                             \"high\": 2}\n",
    "\n",
    "label_to_id_neweducation = {\"someschool\": 0,\n",
    "                            \"highschool\": 1,\n",
    "                            \"collegemore\": 2}\n",
    "\n",
    "prompt_translator = {\"_age_\": \"age\",\n",
    "                     \"_gender_\": \"gender\",\n",
    "                     \"_socioeco_\": \"socioeconomic status\",\n",
    "                     \"_education_\": \"education level\",}\n",
    "\n",
    "openai_dataset = {\"_age_\": \"dataset/openai_age_1/\",\n",
    "                  \"_gender_\": \"dataset/openai_gender_1/\",\n",
    "                  \"_education_\": \"dataset/openai_education_1/\",\n",
    "                  \"_socioeco_\": \"dataset/openai_socioeconomic_1/\",}\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "directories = [\"dataset/llama_age_1/\", \"dataset/llama_gender_1/\",\n",
    "               \"dataset/llama_socioeconomic_1/\", \"dataset/openai_education_1/\"]\n",
    "\n",
    "label_idfs = [\"_age_\", \"_gender_\", \"_socioeco_\", \"_education_\"]\n",
    "\n",
    "label_to_ids = [label_to_id_age, label_to_id_gender,\n",
    "                label_to_id_socioeconomic, label_to_id_neweducation]\n",
    "\n",
    "for directory, label_idf, label_to_id in zip(directories, label_idfs, label_to_ids):\n",
    "    # additional_dataset=[directory[:-1] + \"_additional/\"]\n",
    "    if label_idf == \"_education_\":\n",
    "        additional_dataset=[]\n",
    "    else:\n",
    "        additional_dataset=[directory[:-2] + \"_2/\", openai_dataset[label_idf]]\n",
    "    if label_idf == \"_gender_\":\n",
    "        additional_dataset += [\"dataset/openai_gender_2/\", \"dataset/openai_gender_3/\", \n",
    "                               \"dataset/openai_gender_4\",]\n",
    "    if label_idf == \"_education_\":\n",
    "        additional_dataset += [\"dataset/openai_education_2\", \"dataset/openai_education_3/\"]\n",
    "    if label_idf == \"_socioeco_\":\n",
    "        additional_dataset += [\"dataset/openai_socioeconomic_2/\", \"dataset/openai_socioeconomic_3/\"]\n",
    "    if label_idf == \"_age_\":\n",
    "        additional_dataset += [\"dataset/openai_age_2/\", \"dataset/openai_age_3/\"]\n",
    "        \n",
    "    dataset = TextDataset(directory, tokenizer, model, label_idf=label_idf, label_to_id=label_to_id,\n",
    "                          convert_to_llama2_format=True, additional_datas=additional_dataset, \n",
    "                          new_format=new_prompt_format,\n",
    "                          residual_stream=residual_stream, if_augmented=augmented, \n",
    "                          remove_last_ai_response=remove_last_ai_response, include_inst=include_inst, k=1,\n",
    "                          one_hot=False, last_tok_pos=-1)\n",
    "    dict_name = label_idf.strip(\"_\")\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_idx, val_idx = sklearn.model_selection.train_test_split(list(range(len(dataset))), \n",
    "                                                                  test_size=test_size,\n",
    "                                                                  train_size=train_size,\n",
    "                                                                  random_state=12345,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  stratify=dataset.labels,\n",
    "                                                                 )\n",
    "\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    test_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "    sampler = None\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, sampler=sampler, pin_memory=True, batch_size=200, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, pin_memory=True, batch_size=400, num_workers=1)\n",
    "\n",
    "    loss_func = nn.BCELoss()\n",
    "    torch_device = \"cuda\"\n",
    "\n",
    "    seeds = seeds[:9]\n",
    "    accuracy_dict[dict_name] = []\n",
    "    accuracy_dict[dict_name + \"_final\"] = []\n",
    "    accuracy_dict[dict_name + \"_train\"] = []\n",
    "        \n",
    "    accs = []\n",
    "    final_accs = []\n",
    "    train_accs = []\n",
    "    for i in tqdm(range(0, 41)):\n",
    "        trainer_config = TrainerConfig()\n",
    "        probe = LinearProbeClassification(probe_class=len(label_to_id.keys()), device=\"cuda\", input_dim=5120,\n",
    "                                            logistic=logistic)\n",
    "        optimizer, scheduler = probe.configure_optimizers(trainer_config)\n",
    "        best_acc = 0\n",
    "        max_epoch = 50\n",
    "        verbosity = False\n",
    "        layer_num = i\n",
    "        print(\"-\" * 40 + f\"Layer {layer_num}\" + \"-\" * 40)\n",
    "        for epoch in range(1, max_epoch + 1):\n",
    "            if epoch == max_epoch:\n",
    "                verbosity = True\n",
    "            # Get the train results from training of each epoch\n",
    "            if uncertainty:\n",
    "                train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                        epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                        verbose=verbosity, layer_num=layer_num, \n",
    "                                        return_raw_outputs=True, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "                test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                    return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                    scheduler=scheduler, epoch_num=epoch, num_classes=len(label_to_id.keys()))\n",
    "            else:\n",
    "                train_results = train(probe, torch_device, train_loader, optimizer, \n",
    "                                        epoch, loss_func=loss_func, verbose_interval=None,\n",
    "                                        verbose=verbosity, layer_num=layer_num,\n",
    "                                        return_raw_outputs=True,\n",
    "                                        one_hot=one_hot, num_classes=len(label_to_id.keys()))\n",
    "                test_results = test(probe, torch_device, test_loader, loss_func=loss_func, \n",
    "                                    return_raw_outputs=True, verbose=verbosity, layer_num=layer_num,\n",
    "                                    scheduler=scheduler,\n",
    "                                    one_hot=one_hot, num_classes=len(label_to_id.keys()))\n",
    "\n",
    "            if test_results[1] > best_acc:\n",
    "                best_acc = test_results[1]\n",
    "                torch.save(probe.state_dict(), f\"probe_checkpoints/reading_probe/{dict_name}_probe_at_layer_{layer_num}.pth\")\n",
    "        torch.save(probe.state_dict(), f\"probe_checkpoints/reading_probe/{dict_name}_probe_at_layer_{layer_num}_final.pth\")\n",
    "        \n",
    "        accs.append(best_acc)\n",
    "        final_accs.append(test_results[1])\n",
    "        train_accs.append(train_results[1])\n",
    "        cm = confusion_matrix(test_results[3], test_results[2])\n",
    "        cm_display = ConfusionMatrixDisplay(cm, display_labels=label_to_id.keys()).plot()\n",
    "        plt.show()\n",
    "\n",
    "        accuracy_dict[dict_name].append(accs)\n",
    "        accuracy_dict[dict_name + \"_final\"].append(final_accs)\n",
    "        accuracy_dict[dict_name + \"_train\"].append(train_accs)\n",
    "        \n",
    "        with open(\"probe_checkpoints/reading_probe_experiment.pkl\", \"wb\") as outfile:\n",
    "            pickle.dump(accuracy_dict, outfile)\n",
    "    del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
